import torch
import torch.nn.functional as F

def predict_url_with_temperature(tokenizer, model,url_text, temperature=5.0):  # th·ª≠ T=2.0‚Äì5.0
    # B∆∞·ªõc 1: M√£ h√≥a URL
    inputs = tokenizer(url_text, return_tensors="pt", padding=True, truncation=True)

    # B∆∞·ªõc 2: D·ª± ƒëo√°n b·∫±ng m√¥ h√¨nh
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits.squeeze() / temperature  # ‚ö†Ô∏è L√†m m·ªÅm x√°c su·∫•t b·∫±ng temperature
    probs = F.softmax(logits, dim=0).cpu().numpy()

    # B∆∞·ªõc 3: L·∫•y x√°c su·∫•t c·ªßa hai l·ªõp
    benign_w, mal_w = probs[0], probs[1]

    # B∆∞·ªõc 4: In ra k·∫øt qu·∫£
    print(f"\nüîç URL: {url_text}")
    print(f"‚û°Ô∏è Tr·ªçng s·ªë hi·ªáu ch·ªânh (T={temperature}): [Benign={benign_w:.6f}, Malicious={mal_w:.6f}]")

    # Ph√¢n c·∫•p m·ª©c ƒë·ªô
    if mal_w <= 0.3:
        level = "üü¢ B√¨nh th∆∞·ªùng"
    elif mal_w <= 0.5:
        level = "üü° Nghi ng·ªù nh·∫π"
    elif mal_w <= 0.8:
        level = "üü† Nguy c∆° cao"
    else:
        level = "üî¥ R·∫•t ƒë·ªôc h·∫°i"

    print(f"üìä M·ª©c ƒë·ªô: {level}")
    return level
